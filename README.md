# Nombres completos:
## - Edson Bryan BÃ©jar RomÃ¡n.

----------------------------------

# ðŸ§  Deep Transformer para Series Temporales â€“ Influenza Prevalence Case

Este repositorio contiene la implementaciÃ³n y prueba del modelo **Transformer para series temporales**, me basÃ© en el paper:

> **"Deep Transformer Models for Time Series Forecasting: The Influenza Prevalence Case"**  
> DOI: [10.48550/arXiv.2001.08317](https://doi.org/10.48550/arXiv.2001.08317) y ejecutÃ© el repositorio: [https://github.com/KasperGroesLudvigsen/influenza_transformer/](https://github.com/KasperGroesLudvigsen/influenza_transformer/))

---

## ðŸŽ¯ Objetivo

Ahora, el objetivo, a parte de replicar el modelo propuesto en el artÃ­culo mencionado, evaluando su comportamiento inicial sobre datos de prevalencia de influenza, fue entrenar nbeats con el mismo dataset del paper original y comparar ambos modelos para ver un resultado.

---
## Consideraciones

Para la correcta ejecuciÃ³n de este repositorio, se implementÃ³ varios scripts que no soy originales del repositorio original.
Se implementaron los script de `train.py` con el cual se generÃ³ el archivo ``transformer_timeseries_model.pth``; luego, se implementÃ³ `evaluate.py`, `data_utils.py` y hubo algunas modificaciones en los archivos `positional_encoder.py`, `dataset.py`.


-------------

ðŸ–¥ï¸ Entorno de ejecuciÃ³n:
- CPU (sin GPU)

- Procesador: antiguo

- PyTorch

- Entrenamiento limitado a 5 Ã©pocas (â‰ˆ7 horas)



## ðŸ› ï¸ TecnologÃ­as usadas

- Python 3.10+
- PyTorch
- NumPy
- Matplotlib
- Pandas


-----------------

## ðŸ“ Archivos subidos: 
- train.py.

- evaluate.py.

- dataset.py.

- data_utils.py.

- inference.py.

- inference_example.py.

- positional_encoder.py.

- sandbox.py.
  
- utils.py.

- model / transformer_timeseries.py

> âš ï¸ No se subiÃ³ el archivo generado del entrenamiento`transformer_timeseries_model.pth`.


> Captura de la estructura del proyecto:

> ![Captura de la estructura del proyecto](Img/estructura_repo.jpeg)

## ðŸ“‰ Resultados obtenidos:
- MSE: 335281.37.

- MAE: 578.89.

- RMSE: 579.03.

Las predicciones fueron planas y sobreestimadas debido al bajo nÃºmero de Ã©pocas y las restricciones del entorno. Sin embargo, el modelo se ejecutÃ³ correctamente, y se visualizÃ³ la salida comparando histÃ³rico, real y predicciÃ³n.

ðŸ“¸ Evidencias:

>Captura del entrenamiento de 5 Ã©pocas:

>![Captura del entrenamiento de 5 Ã©pocas](Img/entrenamient_5_epocas.jpeg)

 
>Captura del grÃ¡fico de predicciÃ³n:

> ![Captura del grÃ¡fico de predicciÃ³n](Img/resultados_prediccion.png)


>Captura resultado en consola:

>![Captura del log de consola](Img/resultado_consola.jpeg)



## ðŸ“ˆ Consideraciones futuras:

- Entrenamiento con mÃ¡s Ã©pocas (cuando disponga de mejor hardware).

- Ajustes de hiperparÃ¡metros.

- EvaluaciÃ³n en otros datasets.

- Desarrollo del plan de tesis sobre esta base.


## ðŸ“š Referencia 

> **"Deep Transformer Models for Time Series Forecasting: The Influenza Prevalence Case"**  
> DOI: [10.48550/arXiv.2001.08317](https://doi.org/10.48550/arXiv.2001.08317)

> Github original: [https://github.com/KasperGroesLudvigsen/influenza_transformer/](https://github.com/KasperGroesLudvigsen/influenza_transformer/)
